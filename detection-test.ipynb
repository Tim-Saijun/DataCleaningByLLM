{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting openai\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/30/1d/27c3571504fb6fb1e9f7c906d93590ead22f5f34910489e155ee28512eeb/openai-1.3.5-py3-none-any.whl (220 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m737.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting distro<2,>=1.7.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f4/2c/c90a3adaf0ddb70afe193f5ebfb539612af57cffe677c3126be533df3098/distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tqdm>4 in ./anaconda3/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in ./anaconda3/lib/python3.9/site-packages (from openai) (3.5.0)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/82/61/a5fca4a1e88e40969bbd0cf0d981f3aa76d5057db160b94f49603fc18740/httpx-0.25.1-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m618.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3,>=1.9.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/0a/2b/64066de1c4cf3d4ed623beeb3bbf3f8d0cc26661f1e7d180ec5eb66b75a5/pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m789.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions<5,>=4.5\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./anaconda3/lib/python3.9/site-packages (from anyio<4,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./anaconda3/lib/python3.9/site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in ./anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2022.9.14)\n",
      "Collecting httpcore\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m792.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.14.5\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/2a/b7/f85e5fd4504fae0df3eadd4bf9e0c495ecbdb804dc9be65653119454571e/pydantic_core-2.14.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m767.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m541.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-extensions, h11, distro, annotated-types, pydantic-core, httpcore, pydantic, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "Successfully installed annotated-types-0.6.0 distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.3.5 pydantic-2.5.2 pydantic-core-2.14.5 typing-extensions-4.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置中包含敏感信息，发布时请删除！！\n",
    "config = {\n",
    "    'apikey': '',\n",
    "    'basePath': '',\n",
    "    'apikey1': 'pk-this-is-a-real-free-pool-token-for-everyone',\n",
    "    'apikey2': 'pk-this-is-a-real-free-api-key-pk-for-everyone',\n",
    "    'basePath1': 'https://ai.fakeopen.com/v1'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试API\n",
    "这里测试了三种api，分别是：\n",
    "- 某第三方的转发api\n",
    "- 公共的网页反代api\n",
    "- 公共的网页反代api（120刀额度账号池）\n",
    "\n",
    "结果如下：\n",
    "- 第三方api：正常\n",
    "- 公共api：会返回额外内容\n",
    "- 公共api（120刀额度账号池）：不可用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三方api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=config[\"apikey\"],\n",
    "    base_url=config[\"basePath\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8NyiWvLHvP2dBM7cVsY5sPKJlyWS9', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Here is the corrected data with the errors marked:\\n\\n[0, 0, 0, 1, 0]\\n\\nCorrected Data:\\n1, New York, United States\\n2, London, United Kingdom\\n3, Paris, France\\n4, Tokyo, Japan\\n5, Sydney, Australia\\n\\nExplanation:\\n- In the original data, the country for Tokyo was incorrectly mentioned as China. The correct country for Tokyo is Japan. Therefore, the result for that line is 1, indicating an error.\\n- All other lines have the correct data, so the result for those lines is 0, indicating no errors.', role='assistant', function_call=None, tool_calls=None))], created=1700725632, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=126, prompt_tokens=167, total_tokens=293))\n",
      "Here is the corrected data with the errors marked:\n",
      "\n",
      "[0, 0, 0, 1, 0]\n",
      "\n",
      "Corrected Data:\n",
      "1, New York, United States\n",
      "2, London, United Kingdom\n",
      "3, Paris, France\n",
      "4, Tokyo, Japan\n",
      "5, Sydney, Australia\n",
      "\n",
      "Explanation:\n",
      "- In the original data, the country for Tokyo was incorrectly mentioned as China. The correct country for Tokyo is Japan. Therefore, the result for that line is 1, indicating an error.\n",
      "- All other lines have the correct data, so the result for those lines is 0, indicating no errors.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\\\n",
    "                You need to help find out errors in given data. The first column of data is number, The second column of data is city, the third column of data is the conuntry which the first column belongs to.\\n\\\n",
    "                Desired Format: list format with the result, result has only two values: 0 or 1, when you find an error in a line,the result is 1 , otherwise the result is 0 .\\n\\\n",
    "                Example output: [0,0,0,0,1]\\n\\\n",
    "                Data:\\n\\\n",
    "                1,New York,United States\\n\\\n",
    "                2,London,United Kingdom\\n\\\n",
    "                3,Paris,France\\n\\\n",
    "                4,Tokyo,China\\n\\\n",
    "                5,Sydney,Australia\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(chat_completion)\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回的内容是：\n",
    "```markdown\n",
    "[0, 0, 0, 1, 0]\n",
    "Corrected Data: \n",
    "1, New York, United States\n",
    "2, London, United Kingdom\n",
    "3, Paris, France\n",
    "4, Tokyo, Japan\n",
    "5, Sydney, Australia\n",
    "Explanation:\n",
    "- In the original data, the country for Tokyo was incorrectly mentioned as China. The correct country for Tokyo is Japan. Therefore, the result for that line is 1, indicating an error.\n",
    "- All other lines have the correct data, so the result for those lines is 0, indicating no errors.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8NymJoUgIdaF9G03mzd3Vx9pDf3Ha', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='[1, 0, 0, 1, 0]', role='assistant', function_call=None, tool_calls=None))], created=1700725867, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=15, prompt_tokens=179, total_tokens=194))\n",
      "[1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# 在prompt中限制返回的结果格式\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\\\n",
    "                You need to help find out errors in given data. The first column of data is number, The second column of data is city, the third column of data is the conuntry which the first column belongs to.\\n\\\n",
    "                Desired Format: list format with the result, result has only two values: 0 or 1, when you find an error in a line,the result is 1 , otherwise the result is 0 . Do not give any unnecessary imformation, return list only!\\n\\\n",
    "                Example output: [0,0,0,0,1]\\n\\\n",
    "                Data:\\n\\\n",
    "                1,New York,United States\\n\\\n",
    "                2,London,United Kingdom\\n\\\n",
    "                3,Paris,France\\n\\\n",
    "                4,Tokyo,China\\n\\\n",
    "                5,Sydney,Australia\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(chat_completion)\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加了限制条件\n",
    "```\n",
    " Do not give any unnecessary imformation, return list only!\n",
    " ```\n",
    " 返回结果\n",
    "```markdown\n",
    "[0, 0, 0, 1, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 反代api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=config[\"apikey1\"],\n",
    "    base_url=config[\"basePath1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-qzA46cQPTFYzecl7ibleJRigge0AR', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Certainly, I can help you identify errors in the given data. Here\\'s the corrected list format with the results:\\n\\n```python\\ndata = [\\n    \"1,New York,United States\",\\n    \"2,London,United Kingdom\",\\n    \"3,Paris,France\",\\n    \"4,Tokyo,Japan\",  # Corrected country from China to Japan\\n    \"5,Sydney,Australia\"\\n]\\n\\n# Function to check errors and generate result list\\ndef check_data(data):\\n    results = []\\n    for line in data:\\n        columns = line.split(\\',\\')\\n        if len(columns) == 3:\\n            number, city, country = columns\\n            # Check for errors in the data\\n            if not number.isdigit() or not country.isalpha():\\n                results.append(1)\\n            else:\\n                results.append(0)\\n        else:\\n            results.append(1)\\n    return results\\n\\n# Get the result list\\nresult_list = check_data(data)\\n\\n# Print the result list\\nprint(result_list)\\n```\\n\\nOutput:\\n```python\\n[0, 0, 0, 1, 0]\\n```\\n\\nIn this example, the result list indicates errors with a value of 1 and correct entries with a value of 0. The error in the fourth line is due to the incorrect country (China should be Japan).', role='assistant', function_call=None, tool_calls=None))], created=1700726451, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0))\n",
      "Certainly, I can help you identify errors in the given data. Here's the corrected list format with the results:\n",
      "\n",
      "```python\n",
      "data = [\n",
      "    \"1,New York,United States\",\n",
      "    \"2,London,United Kingdom\",\n",
      "    \"3,Paris,France\",\n",
      "    \"4,Tokyo,Japan\",  # Corrected country from China to Japan\n",
      "    \"5,Sydney,Australia\"\n",
      "]\n",
      "\n",
      "# Function to check errors and generate result list\n",
      "def check_data(data):\n",
      "    results = []\n",
      "    for line in data:\n",
      "        columns = line.split(',')\n",
      "        if len(columns) == 3:\n",
      "            number, city, country = columns\n",
      "            # Check for errors in the data\n",
      "            if not number.isdigit() or not country.isalpha():\n",
      "                results.append(1)\n",
      "            else:\n",
      "                results.append(0)\n",
      "        else:\n",
      "            results.append(1)\n",
      "    return results\n",
      "\n",
      "# Get the result list\n",
      "result_list = check_data(data)\n",
      "\n",
      "# Print the result list\n",
      "print(result_list)\n",
      "```\n",
      "\n",
      "Output:\n",
      "```python\n",
      "[0, 0, 0, 1, 0]\n",
      "```\n",
      "\n",
      "In this example, the result list indicates errors with a value of 1 and correct entries with a value of 0. The error in the fourth line is due to the incorrect country (China should be Japan).\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\\\n",
    "                You need to help find out errors in given data. The first column of data is number, The second column of data is city, the third column of data is the conuntry which the first column belongs to.\\n\\\n",
    "                Desired Format: list format with the result, result has only two values: 0 or 1, when you find an error in a line,the result is 1 , otherwise the result is 0 .\\n\\\n",
    "                Example output: [0,0,0,0,1]\\n\\\n",
    "                Data:\\n\\\n",
    "                1,New York,United States\\n\\\n",
    "                2,London,United Kingdom\\n\\\n",
    "                3,Paris,France\\n\\\n",
    "                4,Tokyo,China\\n\\\n",
    "                5,Sydney,Australia\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(chat_completion)\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回结果：\n",
    "```markdown\n",
    "Certainly, I can help you identify errors in the given data. Here's the corrected list format with the results:\n",
    "\n",
    "```python\n",
    "data = [\n",
    "    \"1,New York,United States\",\n",
    "    \"2,London,United Kingdom\",\n",
    "    \"3,Paris,France\",\n",
    "    \"4,Tokyo,Japan\",  # Corrected country from China to Japan\n",
    "    \"5,Sydney,Australia\"\n",
    "]\n",
    "\n",
    "# Function to check errors and generate result list\n",
    "def check_data(data):\n",
    "    results = []\n",
    "    for line in data:\n",
    "        columns = line.split(',')\n",
    "        if len(columns) == 3:\n",
    "            number, city, country = columns\n",
    "            # Check for errors in the data\n",
    "            if not number.isdigit() or not country.isalpha():\n",
    "                results.append(1)\n",
    "            else:\n",
    "                results.append(0)\n",
    "        else:\n",
    "            results.append(1)\n",
    "    return results\n",
    "\n",
    "# Get the result list\n",
    "result_list = check_data(data)\n",
    "\n",
    "# Print the result list\n",
    "print(result_list)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```python\n",
    "[0, 0, 0, 1, 0]\n",
    "```\n",
    "\n",
    "In this example, the result list indicates errors with a value of 1 and correct entries with a value of 0. The error in the fourth line is due to the incorrect country (China should be Japan).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-D9TM82GwhhNZSGqavDcUU8wfimDDj', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='[0, 0, 0, 1, 0]', role='assistant', function_call=None, tool_calls=None))], created=1700726695, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0))\n",
      "[0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# 在prompt中限制返回的结果格式\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\\\n",
    "                You need to help find out errors in given data. The first column of data is number, The second column of data is city, the third column of data is the conuntry which the first column belongs to.\\n\\\n",
    "                Desired Format: list format with the result, result has only two values: 0 or 1, when you find an error in a line,the result is 1 , otherwise the result is 0 . Do not give any unnecessary imformation, return list only!\\n\\\n",
    "                Example output: [0,0,0,0,1]\\n\\\n",
    "                Data:\\n\\\n",
    "                1,New York,United States\\n\\\n",
    "                2,London,United Kingdom\\n\\\n",
    "                3,Paris,France\\n\\\n",
    "                4,Tokyo,China\\n\\\n",
    "                5,Sydney,Australia\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(chat_completion)\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加了限制条件\n",
    "```\n",
    " Do not give any unnecessary imformation, return list only!\n",
    " ```\n",
    " 返回结果\n",
    "```markdown\n",
    "[0, 0, 0, 1, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 反代账号池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=config[\"apikey2\"],\n",
    "    base_url=config[\"basePath1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'The OpenAI account associated with this API key has been deactivated. If you are the developer for this OpenAI app, please check your email for more information. If you are seeing this error while using another app or site, please reach out to them for more help.', 'type': 'invalid_request_error', 'param': None, 'code': 'account_deactivated'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2401/3361264460.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 在prompt中限制返回的结果格式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m chat_completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m     messages=[\n\u001b[1;32m      4\u001b[0m         {\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 598\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             body=maybe_transform(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         )\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     def patch(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 842\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    843\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    874\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    934\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;31m# to completion before attempting to access the response text.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m             \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'The OpenAI account associated with this API key has been deactivated. If you are the developer for this OpenAI app, please check your email for more information. If you are seeing this error while using another app or site, please reach out to them for more help.', 'type': 'invalid_request_error', 'param': None, 'code': 'account_deactivated'}}"
     ]
    }
   ],
   "source": [
    "# 在prompt中限制返回的结果格式\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\\\n",
    "                You need to help find out errors in given data. The first column of data is number, The second column of data is city, the third column of data is the conuntry which the first column belongs to.\\n\\\n",
    "                Desired Format: list format with the result, result has only two values: 0 or 1, when you find an error in a line,the result is 1 , otherwise the result is 0 . Do not give any unnecessary imformation, return list only!\\n\\\n",
    "                Example output: [0,0,0,0,1]\\n\\\n",
    "                Data:\\n\\\n",
    "                1,New York,United States\\n\\\n",
    "                2,London,United Kingdom\\n\\\n",
    "                3,Paris,France\\n\\\n",
    "                4,Tokyo,China\\n\\\n",
    "                5,Sydney,Australia\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(chat_completion)\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反代的账号池已经不可用，大部分账号都被封禁了，返回结果如下：\n",
    "```json\n",
    "{'error': {'message': 'The OpenAI account associated with this API key has been deactivated. If you are the developer for this OpenAI app, please check your email for more information. If you are seeing this error while using another app or site, please reach out to them for more help.', 'type': 'invalid_request_error', 'param': None, 'code': 'account_deactivated'}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8NzMRwwW4F0PE4KdWvHAtZB4o2519', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='[1, 0, 0, 1, 0]', role='assistant', function_call=None, tool_calls=None))], created=1700728107, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=15, prompt_tokens=179, total_tokens=194))\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=config[\"apikey\"],\n",
    "    base_url=config[\"basePath\"],\n",
    ")\n",
    "# 在prompt中限制返回的结果格式\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\\\n",
    "                You need to help find out errors in given data. The first column of data is number, The second column of data is city, the third column of data is the conuntry which the first column belongs to.\\n\\\n",
    "                Desired Format: list format with the result, result has only two values: 0 or 1, when you find an error in a line,the result is 1 , otherwise the result is 0 . Do not give any unnecessary imformation, return list only!\\n\\\n",
    "                Example output: [0,0,0,0,1]\\n\\\n",
    "                Data:\\n\\\n",
    "                1,New York,United States\\n\\\n",
    "                2,London,United Kingdom\\n\\\n",
    "                3,Paris,France\\n\\\n",
    "                4,Tokyo,China\\n\\\n",
    "                5,Sydney,Australia\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(chat_completion)\n",
    "resp = chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0]\n",
      "丢弃数据： 1\n",
      "丢弃数据： 4\n"
     ]
    }
   ],
   "source": [
    "# 根据返回的结果，丢弃错误的数据\n",
    "import ast\n",
    "resp_list = ast.literal_eval(resp)\n",
    "print(resp_list)\n",
    "index = 1\n",
    "for i in resp_list:\n",
    "    if i == 1:\n",
    "        print(\"丢弃数据：\",index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "GPT返回结果有随机性，即使temperature设置为0，也不一定能得到相同的结果。也许可以通过多次调用API，然后对结果进行统计，最后得到一个最终的结果。\n",
    "\n",
    "反代API的随机性更大，因为相当于是在网页对话，无法自定义system prompt，也无法控制temperature等参数。\n",
    "\n",
    "默认情况下，返回的结果中就会说明错误原因和修正结果，也许detect和repair可以合并?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
